import { Request, Response } from 'express';
import axios from 'axios';
import { db } from '@/db/index';
import { 
  projects, 
  analysis_steps, 
  project_analysis_progress,
  missing_documents,
  strengths_and_weaknesses,
  conversations_with_ai,
  sessions,
  documents,
  conversations,
  CreateAnalysisStepSchema,
  UpdateWorkflowStepSchema,
  InitiateWorkflowSchema,
  GetWorkflowStatusSchema,
  AnalysisMacroPayloadSchema,
  AnalysisDescriptionPayloadSchema,
  MissingDocumentsPayloadSchema,
  StrengthsWeaknessesPayloadSchema,
  FinalMessagePayloadSchema,
  ConsolidatedDataPayloadSchema,
  consolidated_data,
  WorkflowStatus,
  api_configurations
} from '@/db/schema';
import { createZipFromDocuments } from '@/lib/s3';
import { eq, and, asc, desc } from 'drizzle-orm';
import type { 
  CreateAnalysisStepInput,
  UpdateWorkflowStepInput,
  InitiateWorkflowInput,
  ProjectWorkflowStatusResponse,
  AnalysisStepDefinitionResponse,
  ProjectAnalysisProgressResponse,
  WorkflowStepEndpointInput
} from '@shared/types/projects';

/**
 * Fonction utilitaire pour envoyer un prompt √† l'IA externe
 */
const sendPromptToAI = async (prompt: string, projectUniqueId: string, stepId: number, stepName: string, conversationUrl?: string): Promise<{ success: boolean; error?: string; conversationUrl?: string }> => {
  try {
    // R√©cup√©rer la configuration API Python active
    let pythonApiUrl = process.env.AI_INTERFACE_ACTION_URL || process.env.AI_INTERFACE_URL;
    
    if (!pythonApiUrl) {
      try {
        // R√©cup√©rer la configuration depuis la base de donn√©es
        const [config] = await db
          .select()
          .from(api_configurations)
          .where(and(
            eq(api_configurations.name, 'Python API'),
            eq(api_configurations.isActive, true)
          ));
        
        pythonApiUrl = config?.url || 'http://localhost:8000';
      } catch (configError) {
        console.warn('‚ö†Ô∏è Impossible de r√©cup√©rer la configuration API Python, utilisation de l\'URL par d√©faut');
        pythonApiUrl = 'http://localhost:8000';
      }
    }
    
    console.log(`üöÄ Envoi automatique du prompt √† l'IA pour l'√©tape: ${stepName}`);
    if (conversationUrl) {
      console.log(`üîó Continuation de la conversation: ${conversationUrl}`);
    }
    
    // Remplacer les placeholders dans le prompt
    let processedPrompt = prompt.replace(/{projectUniqueId}/g, projectUniqueId);
    
    // Remplacer {documentListUrl} par l'URL de la page des documents
    if (processedPrompt.includes('{documentListUrl}')) {
      const baseUrl = process.env.API_BASE_URL || 'https://ai-bricks-analyst-production.up.railway.app';
      const documentListUrl = `${baseUrl}/api/projects/${projectUniqueId}/documents-list`;
      processedPrompt = processedPrompt.replace(/{documentListUrl}/g, documentListUrl);
    }
    
    // Pr√©parer le payload (m√™me format que le frontend)
    const payload: any = {
      message: processedPrompt,
      platform: 'manus',
      projectUniqueId,
    };

    // Ajouter conversation_url si disponible pour continuer la m√™me session
    if (conversationUrl) {
      payload.conversation_url = conversationUrl;
    }
    
    console.log(`üì° Envoi vers l'API Python: ${pythonApiUrl}`);
    
    // Utiliser directement l'API Python externe
    const response = await axios.post(`${pythonApiUrl}/send-message`, payload, {
      headers: {
        'Content-Type': 'application/json',
      },
      timeout: 30000, // 30 secondes de timeout pour les t√¢ches IA
    });

    if (response.data && response.data.conversation_url) {
      console.log(`‚úÖ Prompt envoy√© avec succ√®s √† l'IA pour l'√©tape: ${stepName}`);
      console.log(`üîó URL conversation retourn√©e: ${response.data.conversation_url}`);
      return {
        success: true,
        conversationUrl: response.data.conversation_url
      };
    } else {
      console.error(`‚ùå R√©ponse inattendue de l'API Python pour l'√©tape ${stepName}:`, response.data);
      return {
        success: false,
        error: 'R√©ponse inattendue de l\'API Python'
      };
    }
  } catch (error: any) {
    console.error(`‚ùå Erreur lors de l'envoi du prompt √† l'IA pour l'√©tape ${stepName}:`, error.message);
    return {
      success: false,
      error: error.message || 'Erreur de connexion √† l\'API Python'
    };
  }
};

/**
 * Fonction utilitaire pour d√©clencher automatiquement l'√©tape suivante du workflow
 */
const triggerNextWorkflowStep = async (projectUniqueId: string, currentStepId: number): Promise<{ success: boolean; error?: string; conversationUrl?: string }> => {
  try {
    console.log(`üîÑ D√©clenchement automatique de l'√©tape suivante pour le projet: ${projectUniqueId}, √©tape courante: ${currentStepId}`);
    
    // R√©cup√©rer le projet
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return { success: false, error: 'Projet non trouv√©' };
    }

    // R√©cup√©rer l'√©tape suivante (order = currentStepId + 1)
    const nextStep = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, currentStepId + 1),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (nextStep.length === 0) {
      console.log(`‚úÖ Aucune √©tape suivante trouv√©e pour l'ordre ${currentStepId + 1}. Workflow termin√©.`);
      return { success: true };
    }

    // V√©rifier que l'√©tape suivante existe dans le workflow du projet
    const nextWorkflowStep = await db
      .select()
      .from(project_analysis_progress)
      .where(and(
        eq(project_analysis_progress.projectId, project[0].id),
        eq(project_analysis_progress.stepId, nextStep[0].id)
      ))
      .limit(1);

    if (nextWorkflowStep.length === 0) {
      return { success: false, error: '√âtape suivante non trouv√©e dans le workflow du projet' };
    }

    // V√©rifier que l'√©tape suivante est en statut 'pending'
    if (nextWorkflowStep[0].status !== 'pending') {
      console.log(`‚ö†Ô∏è L'√©tape suivante n'est pas en statut 'pending' (statut actuel: ${nextWorkflowStep[0].status})`);
      return { success: true }; // Pas d'erreur, mais pas de d√©clenchement
    }

    // Mettre l'√©tape suivante en statut 'in_progress'
    await db
      .update(project_analysis_progress)
      .set({
        status: 'in_progress',
        updatedAt: new Date(),
      })
      .where(eq(project_analysis_progress.id, nextWorkflowStep[0].id));

    // R√©cup√©rer l'URL de conversation de l'√©tape pr√©c√©dente si disponible
    // Note: Pour l'instant, nous utilisons la conversation la plus r√©cente du projet
    const previousConversation = await db
      .select()
      .from(conversations_with_ai)
      .innerJoin(sessions, eq(conversations_with_ai.sessionId, sessions.id))
      .where(eq(sessions.projectId, project[0].id))
      .orderBy(desc(conversations_with_ai.createdAt))
      .limit(1);

    const conversationUrl = previousConversation.length > 0 ? previousConversation[0].conversations_with_ai.url : undefined;

    // Envoyer le prompt √† l'IA pour l'√©tape suivante
    const aiResult = await sendPromptToAI(
      nextStep[0].prompt,
      projectUniqueId,
      nextStep[0].id,
      nextStep[0].name,
      conversationUrl
    );

    if (aiResult.success) {
      console.log(`‚úÖ √âtape suivante "${nextStep[0].name}" d√©clench√©e avec succ√®s`);
      
      // Sauvegarder l'URL de conversation si disponible
      if (aiResult.conversationUrl) {
        console.log(`üíæ URL de conversation disponible: ${aiResult.conversationUrl}`);
        await db
          .update(project_analysis_progress)
          .set({
            manusConversationUrl: aiResult.conversationUrl,
            updatedAt: new Date(),
          })
          .where(eq(project_analysis_progress.id, nextWorkflowStep[0].id));
      }
    } else {
      console.error(`‚ùå Erreur lors du d√©clenchement de l'√©tape suivante: ${aiResult.error}`);
      
      // Marquer l'√©tape comme √©chou√©e avec le message d'erreur
      await db
        .update(project_analysis_progress)
        .set({
          status: 'failed',
          content: `Erreur lors de l'envoi du prompt √† l'API Python: ${aiResult.error}`,
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, nextWorkflowStep[0].id));
    }

    return aiResult;
  } catch (error) {
    console.error(`‚ùå Erreur lors du d√©clenchement automatique de l'√©tape suivante:`, error);
    return { success: false, error: (error as Error).message };
  }
};

/**
 * Initialise les √©tapes d'analyse par d√©faut dans la base de donn√©es
 * Cette fonction doit √™tre appel√©e au d√©marrage de l'application
 */
export const initializeDefaultAnalysisSteps = async (): Promise<void> => {
  try {
    // V√©rifier si les √©tapes existent d√©j√†
    const existingSteps = await db.select().from(analysis_steps).limit(1);
    
    if (existingSteps.length === 0) {
      // Cr√©er les 5 √©tapes par d√©faut
          // Les prompts sont g√©r√©s par l'interface AI et mis √† jour via des scripts d√©di√©s
    // Ne pas d√©finir de prompts ici pour √©viter les confusions
    const defaultSteps = [
      {
        name: 'Upload des documents',
        description: 'G√©n√®re un fichier ZIP contenant tous les documents du projet et l\'envoie √† Manus pour analyse',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 0,
        isActive: 1
      },
      {
        name: 'Analyse globale',
        description: 'Une analyse d√©taill√©e et approfondie du projet avec vue d\'ensemble',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 1,
        isActive: 1
      },
      {
        name: 'Consolidation des donn√©es',
        description: 'R√©cup√®re et structure toutes les donn√©es cl√©s n√©cessaires √† l\'analyse',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 2,
        isActive: 1
      },
      {
        name: 'R√©cup√©ration des documents manquants',
        description: 'Liste des documents attendus en compl√©ment pour approfondir l\'analyse',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 3,
        isActive: 1
      },
      {
        name: 'Points de vigilance',
        description: 'Identification des risques critiques qui pourraient compromettre le financement',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 4,
        isActive: 1
      },
      {
        name: 'R√©daction d\'un message',
        description: 'Un message qui r√©capitule le projet et liste les documents manquants',
        prompt: 'PROMPT_MANAGED_BY_AI_INTERFACE', // G√©r√© par l'interface AI
        order: 5,
        isActive: 1
      }
    ];

      await db.insert(analysis_steps).values(defaultSteps);
      console.log('‚úÖ √âtapes d\'analyse par d√©faut cr√©√©es avec succ√®s');
    }
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'initialisation des √©tapes d\'analyse:', error);
  }
};

/**
 * Cr√©e une nouvelle √©tape d'analyse
 * @route POST /api/workflow/steps
 */
export const createAnalysisStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const validatedData = CreateAnalysisStepSchema.parse(req.body);
    const stepData: CreateAnalysisStepInput = validatedData;

    const newStep = await db
      .insert(analysis_steps)
      .values({
        name: stepData.name,
        description: stepData.description,
        prompt: stepData.prompt,
        order: stepData.order,
        isActive: stepData.isActive ?? 1,
        createdAt: new Date(),
      })
      .returning();

    res.status(201).json(newStep[0]);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'CREATE_ANALYSIS_STEP_ERROR'
    });
  }
};

/**
 * Met √† jour une √©tape d'analyse existante
 * @route PUT /api/workflow/steps/:id
 */
export const updateAnalysisStepDefinition = async (req: Request, res: Response): Promise<any> => {
  try {
    const stepId = parseInt(req.params.id);
    const validatedData = CreateAnalysisStepSchema.parse(req.body);
    const stepData: CreateAnalysisStepInput = validatedData;

    // V√©rifier que l'√©tape existe
    const existingStep = await db
      .select()
      .from(analysis_steps)
      .where(eq(analysis_steps.id, stepId))
      .limit(1);

    if (existingStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    // Mettre √† jour l'√©tape
    const updatedStep = await db
      .update(analysis_steps)
      .set({
        name: stepData.name,
        description: stepData.description,
        prompt: stepData.prompt,
        order: stepData.order,
        isActive: stepData.isActive ?? 1,
      })
      .where(eq(analysis_steps.id, stepId))
      .returning();

    res.json(updatedStep[0]);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_ANALYSIS_STEP_ERROR'
    });
  }
};

/**
 * R√©cup√®re toutes les √©tapes d'analyse actives
 * @route GET /api/workflow/steps
 */
export const getAllAnalysisSteps = async (req: Request, res: Response): Promise<any> => {
  try {
    const steps = await db
      .select()
      .from(analysis_steps)
      .where(eq(analysis_steps.isActive, 1))
      .orderBy(asc(analysis_steps.order));

    res.json(steps);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'GET_ANALYSIS_STEPS_ERROR'
    });
  }
};

/**
 * Fonction utilitaire pour initier le workflow d'un projet
 * Peut √™tre utilis√©e par l'API et par d'autres fonctions internes
 */
export const initiateWorkflowForProject = async (projectUniqueId: string): Promise<{ success: boolean; stepsCreated?: number; error?: string }> => {
  try {
    // V√©rifier que le projet existe
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return { success: false, error: 'Projet non trouv√©' };
    }

    // R√©cup√©rer toutes les √©tapes actives
    const steps = await db
      .select()
      .from(analysis_steps)
      .where(eq(analysis_steps.isActive, 1))
      .orderBy(asc(analysis_steps.order));

    // V√©rifier si le workflow existe d√©j√†
    const existingWorkflow = await db
      .select()
      .from(project_analysis_progress)
      .where(eq(project_analysis_progress.projectId, project[0].id))
      .limit(1);

    if (existingWorkflow.length > 0) {
      return { success: false, error: 'Le workflow d\'analyse est d√©j√† initi√© pour ce projet' };
    }

    // Cr√©er les entr√©es de workflow pour chaque √©tape
    const workflowEntries = steps.map(step => ({
      projectId: project[0].id,
      stepId: step.id,
      status: 'pending' as const,
      createdAt: new Date(),
      updatedAt: new Date(),
    }));

    const createdWorkflow = await db
      .insert(project_analysis_progress)
      .values(workflowEntries)
      .returning();

    return { success: true, stepsCreated: createdWorkflow.length };
  } catch (error) {
    return { success: false, error: (error as Error).message };
  }
};

/**
 * Initie le workflow d'analyse pour un projet
 * @route POST /api/workflow/initiate
 */
export const initiateWorkflow = async (req: Request, res: Response): Promise<any> => {
  try {
    const validatedData = InitiateWorkflowSchema.parse(req.body);
    const { projectUniqueId }: InitiateWorkflowInput = validatedData;

    const result = await initiateWorkflowForProject(projectUniqueId);

    if (!result.success) {
      const statusCode = result.error?.includes('non trouv√©') ? 404 : 
                        result.error?.includes('d√©j√† initi√©') ? 409 : 500;
      return res.status(statusCode).json({ 
        error: result.error,
        code: statusCode === 404 ? 'PROJECT_NOT_FOUND' : 
              statusCode === 409 ? 'WORKFLOW_ALREADY_EXISTS' : 'INITIATE_WORKFLOW_ERROR'
      });
    }

    res.status(201).json({
      message: 'Workflow d\'analyse initi√© avec succ√®s',
      projectUniqueId,
      stepsCreated: result.stepsCreated
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'INITIATE_WORKFLOW_ERROR'
    });
  }
};

/**
 * R√©cup√®re le statut du workflow d'analyse pour un projet
 * @route GET /api/workflow/status/:projectUniqueId
 */
export const getWorkflowStatus = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const validatedData = GetWorkflowStatusSchema.parse({ projectUniqueId });

    // R√©cup√©rer le projet
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, validatedData.projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // R√©cup√©rer le workflow avec les √©tapes
    const workflowSteps = await db
      .select({
        workflow: project_analysis_progress,
        step: analysis_steps
      })
      .from(project_analysis_progress)
      .leftJoin(analysis_steps, eq(project_analysis_progress.stepId, analysis_steps.id))
      .where(eq(project_analysis_progress.projectId, project[0].id))
      .orderBy(asc(analysis_steps.order));

    if (workflowSteps.length === 0) {
      return res.status(404).json({ 
        error: 'Workflow non initi√© pour ce projet',
        code: 'WORKFLOW_NOT_FOUND'
      });
    }

    // Calculer le statut global
    const completedSteps = workflowSteps.filter(ws => ws.workflow.status === 'completed').length;
    const failedSteps = workflowSteps.filter(ws => ws.workflow.status === 'failed').length;
    const inProgressSteps = workflowSteps.filter(ws => ws.workflow.status === 'in_progress').length;

    let overallStatus: 'not_started' | 'in_progress' | 'completed' | 'failed';
    if (failedSteps > 0) {
      overallStatus = 'failed';
    } else if (completedSteps === workflowSteps.length) {
      overallStatus = 'completed';
    } else if (inProgressSteps > 0 || completedSteps > 0) {
      overallStatus = 'in_progress';
    } else {
      overallStatus = 'not_started';
    }

    // Trouver l'√©tape courante (premi√®re √©tape non compl√©t√©e)
    const currentStepData = workflowSteps.find(ws => 
      ws.workflow.status === 'pending' || ws.workflow.status === 'in_progress'
    );

    const response: ProjectWorkflowStatusResponse = {
      projectUniqueId: validatedData.projectUniqueId,
      projectId: project[0].id,
      steps: workflowSteps.map(ws => ({
        ...ws.workflow,
        status: ws.workflow.status as 'pending' | 'in_progress' | 'completed' | 'failed',
        step: ws.step!
      })),
      overallStatus,
      completedSteps,
      totalSteps: workflowSteps.length,
      currentStep: currentStepData ? {
        ...currentStepData.workflow,
        status: currentStepData.workflow.status as 'pending' | 'in_progress' | 'completed' | 'failed',
        step: currentStepData.step!
      } : null
    };

    res.json(response);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'GET_WORKFLOW_STATUS_ERROR'
    });
  }
};

/**
 * Met √† jour le statut d'une √©tape de workflow
 * @route POST /api/workflow/update-step
 */
export const updateWorkflowStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const validatedData = UpdateWorkflowStepSchema.parse(req.body);
    const stepData: UpdateWorkflowStepInput = validatedData;

    // R√©cup√©rer le projet
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, stepData.projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // V√©rifier que l'√©tape de workflow existe
    const workflowStep = await db
      .select()
      .from(project_analysis_progress)
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(project_analysis_progress.stepId, stepData.stepId)
        )
      )
      .limit(1);

    if (workflowStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape de workflow non trouv√©e',
        code: 'WORKFLOW_STEP_NOT_FOUND'
      });
    }

    // Pr√©parer les donn√©es de mise √† jour
    const updateData: any = {
      status: stepData.status,
      updatedAt: new Date(),
    };

    if (stepData.content !== undefined) {
      updateData.content = stepData.content;
    }

    if (stepData.manusConversationUrl !== undefined) {
      updateData.manusConversationUrl = stepData.manusConversationUrl;
    }

    if (stepData.status === 'in_progress' && !workflowStep[0].startedAt) {
      updateData.startedAt = new Date();
    }

    if (stepData.status === 'completed' || stepData.status === 'failed') {
      updateData.completedAt = new Date();
    }

    // Mettre √† jour l'√©tape
    const updatedStep = await db
      .update(project_analysis_progress)
      .set(updateData)
      .where(eq(project_analysis_progress.id, workflowStep[0].id))
      .returning();

    // ‚úÖ NOUVEAU: D√©clencher automatiquement l'√©tape suivante si l'√©tape est marqu√©e comme 'completed'
    let nextStepTriggered = false;
    if (stepData.status === 'completed') {
      try {
        // R√©cup√©rer l'ordre de l'√©tape courante
        const currentStep = await db
          .select()
          .from(analysis_steps)
          .where(eq(analysis_steps.id, stepData.stepId))
          .limit(1);

        if (currentStep.length > 0) {
          const triggerResult = await triggerNextWorkflowStep(stepData.projectUniqueId, currentStep[0].order);
          nextStepTriggered = triggerResult.success;
          
          if (!triggerResult.success) {
            console.warn(`‚ö†Ô∏è √âchec du d√©clenchement automatique de l'√©tape suivante: ${triggerResult.error}`);
          } else {
            console.log(`‚úÖ √âtape suivante d√©clench√©e automatiquement apr√®s completion de l'√©tape ${currentStep[0].order}`);
          }
        }
      } catch (triggerError) {
        console.error('‚ùå Erreur lors du d√©clenchement automatique de l\'√©tape suivante:', triggerError);
        // Ne pas faire √©chouer la mise √† jour principale
      }
    }

    res.json({
      message: '√âtape de workflow mise √† jour avec succ√®s',
      step: updatedStep[0],
      nextStepTriggered
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_WORKFLOW_STEP_ERROR'
    });
  }
};

// Endpoints structur√©s pour les analyses IA avec d√©clenchement automatique

/**
 * Endpoint pour recevoir les donn√©es consolid√©es de l'IA (√âtape 2)
 * @route POST /api/workflow/consolidated-data/:projectUniqueId
 */
export const receiveConsolidatedData = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const validatedData = ConsolidatedDataPayloadSchema.parse({ 
      ...req.body, 
      projectUniqueId 
    });

    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // Trouver l'√©tape de consolidation des donn√©es (√©tape avec order = 2)
    const workflowStep = await db
      .select({
        workflow: project_analysis_progress,
        step: analysis_steps
      })
      .from(project_analysis_progress)
      .leftJoin(analysis_steps, eq(project_analysis_progress.stepId, analysis_steps.id))
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(analysis_steps.order, 2) // √âtape avec order = 2 = consolidation des donn√©es
        )
      )
      .limit(1);

    if (workflowStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape de workflow non trouv√©e. Initialisez d\'abord le workflow.',
        code: 'WORKFLOW_STEP_NOT_FOUND'
      });
    }

    // Pr√©parer les donn√©es √† ins√©rer/mettre √† jour
    const consolidatedDataToInsert = {
      projectId: project[0].id,
      // Donn√©es Financi√®res
      financialAcquisitionPrice: validatedData.consolidatedData.financial?.acquisitionPrice?.toString(),
      financialWorksCost: validatedData.consolidatedData.financial?.worksCost?.toString(),
      financialPlannedResalePrice: validatedData.consolidatedData.financial?.plannedResalePrice?.toString(),
      financialPersonalContribution: validatedData.consolidatedData.financial?.personalContribution?.toString(),
      // Donn√©es du Bien
      propertyLivingArea: validatedData.consolidatedData.property?.livingArea?.toString(),
      propertyMarketReferencePrice: validatedData.consolidatedData.property?.marketReferencePrice?.toString(),
      propertyMonthlyRentExcludingTax: validatedData.consolidatedData.property?.monthlyRentExcludingTax?.toString(),
      propertyPresoldUnits: validatedData.consolidatedData.property?.presoldUnits,
      propertyTotalUnits: validatedData.consolidatedData.property?.totalUnits,
      propertyPreMarketingRate: validatedData.consolidatedData.property?.preMarketingRate?.toString(),
      // Donn√©es Porteur
      carrierExperienceYears: validatedData.consolidatedData.carrier?.experienceYears,
      carrierSuccessfulOperations: validatedData.consolidatedData.carrier?.successfulOperations,
      carrierHasActiveLitigation: validatedData.consolidatedData.carrier?.hasActiveLitigation,
      // Soci√©t√© Porteuse
      companyYearsOfExistence: validatedData.consolidatedData.company?.yearsOfExistence,
      companyNetResultYear1: validatedData.consolidatedData.company?.netResultYear1?.toString(),
      companyNetResultYear2: validatedData.consolidatedData.company?.netResultYear2?.toString(),
      companyNetResultYear3: validatedData.consolidatedData.company?.netResultYear3?.toString(),
      companyTotalDebt: validatedData.consolidatedData.company?.totalDebt?.toString(),
      companyEquity: validatedData.consolidatedData.company?.equity?.toString(),
      companyDebtRatio: validatedData.consolidatedData.company?.debtRatio?.toString(),
      updatedAt: new Date(),
    };

    // Ins√©rer ou mettre √† jour les donn√©es consolid√©es (upsert)
    await db
      .insert(consolidated_data)
      .values({
        ...consolidatedDataToInsert,
        createdAt: new Date(),
      })
      .onConflictDoUpdate({
        target: consolidated_data.projectId,
        set: consolidatedDataToInsert
      });

    // Mettre √† jour l'√©tape du workflow
    const updatedStep = await db
      .update(project_analysis_progress)
      .set({
        status: 'completed',
        content: JSON.stringify(validatedData.consolidatedData),
        completedAt: new Date(),
        updatedAt: new Date(),
      })
      .where(eq(project_analysis_progress.id, workflowStep[0].workflow.id))
      .returning();

    // D√©clencher automatiquement l'√©tape suivante (ordre 3 - Documents manquants)
    const triggerResult = await triggerNextWorkflowStep(projectUniqueId, 2);
    if (!triggerResult.success) {
      console.warn(`‚ö†Ô∏è √âchec du d√©clenchement automatique de l'√©tape suivante: ${triggerResult.error}`);
    }

    res.status(200).json({
      success: true,
      message: 'Donn√©es consolid√©es re√ßues et enregistr√©es avec succ√®s',
      workflowStepId: updatedStep[0].id,
      data: validatedData.consolidatedData,
      nextStepTriggered: triggerResult.success
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'RECEIVE_CONSOLIDATED_DATA_ERROR'
    });
  }
};

// Endpoints sp√©cifiques pour chaque √©tape (appel√©s par Manus)

/**
 * Endpoint pour l'√©tape 1: Vue d'ensemble du projet
 * @route POST /api/workflow/step-1-overview
 */
export const updateOverviewStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId, content, manusConversationUrl }: WorkflowStepEndpointInput = req.body;

    // R√©cup√©rer le vrai stepId de l'√©tape avec order = 1
    const step = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 1),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 1)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const updateData: UpdateWorkflowStepInput = {
      projectUniqueId,
      stepId: step[0].id, // Utiliser le vrai ID au lieu de l'order
      status: 'completed',
      content,
      manusConversationUrl
    };

    // R√©utiliser la logique de updateWorkflowStep
    req.body = updateData;
    return await updateWorkflowStep(req, res);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_OVERVIEW_STEP_ERROR'
    });
  }
};

/**
 * Endpoint pour l'√©tape 2: Analyse globale
 * @route POST /api/workflow/step-2-analysis
 */
export const updateAnalysisStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId, content, manusConversationUrl }: WorkflowStepEndpointInput = req.body;

    // R√©cup√©rer le vrai stepId de l'√©tape avec order = 2
    const step = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 2),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 2)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const updateData: UpdateWorkflowStepInput = {
      projectUniqueId,
      stepId: step[0].id, // Utiliser le vrai ID au lieu de l'order
      status: 'completed',
      content,
      manusConversationUrl
    };

    req.body = updateData;
    return await updateWorkflowStep(req, res);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_ANALYSIS_STEP_ERROR'
    });
  }
};

/**
 * Endpoint pour l'√©tape 3: R√©cup√©ration des documents manquants
 * @route POST /api/workflow/step-3-documents
 */
export const updateDocumentsStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId, content, manusConversationUrl }: WorkflowStepEndpointInput = req.body;

    // R√©cup√©rer le vrai stepId de l'√©tape avec order = 3
    const step = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 3),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 3)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const updateData: UpdateWorkflowStepInput = {
      projectUniqueId,
      stepId: step[0].id, // Utiliser le vrai ID au lieu de l'order
      status: 'completed',
      content,
      manusConversationUrl
    };

    req.body = updateData;
    return await updateWorkflowStep(req, res);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_DOCUMENTS_STEP_ERROR'
    });
  }
};

/**
 * Endpoint pour l'√©tape 4: Points de vigilance
 * @route POST /api/workflow/step-4-vigilance
 */
export const updateVigilanceStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId, content, manusConversationUrl }: WorkflowStepEndpointInput = req.body;

    // R√©cup√©rer le vrai stepId de l'√©tape avec order = 4
    const step = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 4),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 4)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const updateData: UpdateWorkflowStepInput = {
      projectUniqueId,
      stepId: step[0].id, // Utiliser le vrai ID au lieu de l'order
      status: 'completed',
      content,
      manusConversationUrl
    };

    req.body = updateData;
    return await updateWorkflowStep(req, res);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_VIGILANCE_STEP_ERROR'
    });
  }
};

/**
 * Endpoint pour l'√©tape 5: R√©daction d'un message
 * @route POST /api/workflow/step-5-message
 */
export const updateMessageStep = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId, content, manusConversationUrl }: WorkflowStepEndpointInput = req.body;

    // R√©cup√©rer le vrai stepId de l'√©tape avec order = 5
    const step = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 5),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 5)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const updateData: UpdateWorkflowStepInput = {
      projectUniqueId,
      stepId: step[0].id, // Utiliser le vrai ID au lieu de l'order
      status: 'completed',
      content,
      manusConversationUrl
    };

    req.body = updateData;
    return await updateWorkflowStep(req, res);
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'UPDATE_MESSAGE_STEP_ERROR'
    });
  }
};

// Nouveaux endpoints pour les analyses IA structur√©es

/**
 * Endpoint pour recevoir l'analyse macro de l'IA (√âtape 1)
 * @route POST /api/workflow/analysis-macro/:projectUniqueId
 */
export const receiveAnalysisMacro = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const validatedData = AnalysisMacroPayloadSchema.parse({ 
      ...req.body, 
      projectUniqueId 
    });

    // V√©rifier que le projet existe
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // Trouver l'√©tape d'analyse macro (√©tape avec order = 1, qui est "Analyse globale")
    const workflowStep = await db
      .select({
        workflow: project_analysis_progress,
        step: analysis_steps
      })
      .from(project_analysis_progress)
      .leftJoin(analysis_steps, eq(project_analysis_progress.stepId, analysis_steps.id))
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(analysis_steps.order, 1) // √âtape avec order = 1 = analyse macro
        )
      )
      .limit(1);

    if (workflowStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape de workflow non trouv√©e. Initialisez d\'abord le workflow.',
        code: 'WORKFLOW_STEP_NOT_FOUND'
      });
    }

    // Mettre √† jour l'√©tape avec les donn√©es de l'analyse macro
    const updatedStep = await db
      .update(project_analysis_progress)
      .set({
        status: 'completed',
        content: JSON.stringify(validatedData.macroAnalysis),
        completedAt: new Date(),
        updatedAt: new Date(),
      })
      .where(eq(project_analysis_progress.id, workflowStep[0].workflow.id))
      .returning();

    // Mettre √† jour la description du projet avec l'analyse macro
    await db
      .update(projects)
      .set({
        description: validatedData.macroAnalysis,
        updatedAt: new Date(),
      })
      .where(eq(projects.id, project[0].id));

    // D√©clencher automatiquement l'√©tape suivante (ordre 2 - Consolidation des donn√©es)
    const triggerResult = await triggerNextWorkflowStep(projectUniqueId, 1);
    if (!triggerResult.success) {
      console.warn(`‚ö†Ô∏è √âchec du d√©clenchement automatique de l'√©tape suivante: ${triggerResult.error}`);
    }

    res.status(200).json({
      success: true,
      message: 'Analyse macro re√ßue et enregistr√©e avec succ√®s',
      workflowStepId: updatedStep[0].id,
      data: validatedData.macroAnalysis
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'RECEIVE_ANALYSIS_MACRO_ERROR'
    });
  }
};

/**
 * Endpoint pour recevoir les documents manquants de l'IA (√âtape 3)
 * @route POST /api/workflow/missing-documents/:projectUniqueId
 */
export const receiveMissingDocuments = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const { skipAutoTrigger } = req.query; // ‚úÖ Nouveau param√®tre pour le mode debug
    const validatedData = MissingDocumentsPayloadSchema.parse({ 
      ...req.body, 
      projectUniqueId 
    });

    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // ‚úÖ √âCRASEMENT : Supprimer les documents manquants existants pour ce projet
    await db
      .delete(missing_documents)
      .where(eq(missing_documents.projectId, project[0].id));

    console.log(`üóëÔ∏è Documents manquants existants supprim√©s pour le projet ${projectUniqueId}`);

    // Cr√©er les nouveaux documents manquants
    const documentsToCreate = validatedData.missingDocuments.map(doc => ({
      projectId: project[0].id,
      name: doc.name,
      whyMissing: doc.whyMissing,
      impactOnProject: doc.impactOnProject || doc.whyMissing, // Utiliser whyMissing si impactOnProject n'est pas fourni
      status: 'pending' as const,
      whyStatus: '',
      createdAt: new Date(),
      updatedAt: new Date(),
    }));

    const createdDocuments = await db
      .insert(missing_documents)
      .values(documentsToCreate)
      .returning();

    console.log(`‚úÖ ${createdDocuments.length} nouveaux documents manquants cr√©√©s pour le projet ${projectUniqueId}`);

    // R√©cup√©rer l'√©tape d'analyse avec order = 3 (documents manquants)
    const analysisStep = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 3),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (analysisStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 3)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    // Mettre √† jour l'√©tape du workflow
    const workflowStep = await db
      .select()
      .from(project_analysis_progress)
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(project_analysis_progress.stepId, analysisStep[0].id) // Utiliser le vrai stepId
        )
      )
      .limit(1);

    if (workflowStep.length > 0) {
      await db
        .update(project_analysis_progress)
        .set({
          status: 'completed',
          content: JSON.stringify(validatedData.missingDocuments),
          completedAt: new Date(),
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, workflowStep[0].id));
    }

    // ‚úÖ D√©clencher automatiquement l'√©tape suivante seulement si pas en mode debug
    let nextStepTriggered = false;
    if (skipAutoTrigger !== 'true') {
      const triggerResult = await triggerNextWorkflowStep(projectUniqueId, 3);
      nextStepTriggered = triggerResult.success;
      if (!triggerResult.success) {
        console.warn(`‚ö†Ô∏è √âchec du d√©clenchement automatique de l'√©tape suivante: ${triggerResult.error}`);
      } else {
        console.log(`‚úÖ √âtape suivante d√©clench√©e automatiquement (mode normal)`);
      }
    } else {
      console.log(`üîß Mode debug activ√© - √©tape suivante non d√©clench√©e automatiquement`);
    }

    res.status(200).json({
      success: true,
      message: 'Documents manquants re√ßus et enregistr√©s avec succ√®s',
      workflowStepId: workflowStep.length > 0 ? workflowStep[0].id : null,
      documentsCreated: createdDocuments.length,
      data: createdDocuments.map(doc => ({
        id: doc.id,
        name: doc.name,
        status: doc.status
      })),
      nextStepTriggered,
      debugMode: skipAutoTrigger === 'true'
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'RECEIVE_MISSING_DOCUMENTS_ERROR'
    });
  }
};

/**
 * Endpoint de test pour voir comment les placeholders sont remplac√©s dans un prompt
 * @route GET /api/workflow/test-prompt/:projectUniqueId
 */
export const testPromptProcessing = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const { prompt } = req.query;

    if (!prompt || typeof prompt !== 'string') {
      return res.status(400).json({ 
        error: 'Le param√®tre "prompt" est requis',
        code: 'MISSING_PROMPT'
      });
    }

    // G√©n√©rer l'URL de la page des documents si le placeholder {documentListUrl} est pr√©sent
    let documentListUrl = '';
    if (prompt.includes('{documentListUrl}')) {
      // URL de base de l'API (√† configurer selon l'environnement)
      const baseUrl = process.env.API_BASE_URL || 'https://ai-bricks-analyst-production.up.railway.app';
      documentListUrl = `${baseUrl}/api/projects/${projectUniqueId}/documents-list`;
    }
    
    // Remplacer les placeholders dans le prompt
    let processedPrompt = prompt.replace(/{projectUniqueId}/g, projectUniqueId);
    processedPrompt = processedPrompt.replace(/{documentListUrl}/g, documentListUrl);

    res.json({
      originalPrompt: prompt,
      processedPrompt: processedPrompt,
      replacements: {
        projectUniqueId: projectUniqueId,
        documentListUrl: documentListUrl || 'Non utilis√©'
      }
    });

  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'TEST_PROMPT_ERROR'
    });
  }
};

/**
 * Endpoint pour recevoir les forces et faiblesses de l'IA (√âtape 4)
 * @route POST /api/workflow/strengths-and-weaknesses/:projectUniqueId
 */
export const receiveStrengthsAndWeaknesses = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const { skipAutoTrigger } = req.query; // ‚úÖ Nouveau param√®tre pour le mode debug
    const validatedData = StrengthsWeaknessesPayloadSchema.parse({ 
      ...req.body, 
      projectUniqueId 
    });

    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // ‚úÖ √âCRASEMENT : Supprimer les forces/faiblesses existantes pour ce projet
    await db
      .delete(strengths_and_weaknesses)
      .where(eq(strengths_and_weaknesses.projectId, project[0].id));

    console.log(`üóëÔ∏è Forces/faiblesses existantes supprim√©es pour le projet ${projectUniqueId}`);

    // Cr√©er les nouvelles forces et faiblesses
    const itemsToCreate = validatedData.strengthsAndWeaknesses.map((item: any) => ({
      projectId: project[0].id,
      type: item.type,
      title: item.title,
      description: item.description,
      riskLevel: 'medium' as const, // Valeur par d√©faut
      potentialImpact: '',
      recommendations: [],
      status: 'pending' as const,
      whyStatus: '',
      createdAt: new Date(),
      updatedAt: new Date(),
    }));

    const createdItems = await db
      .insert(strengths_and_weaknesses)
      .values(itemsToCreate)
      .returning();

    console.log(`‚úÖ ${createdItems.length} nouvelles forces/faiblesses cr√©√©es pour le projet ${projectUniqueId}`);

    // R√©cup√©rer l'√©tape d'analyse avec order = 4 (points de vigilance)
    const analysisStep = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 4),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (analysisStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 4)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    // Mettre √† jour l'√©tape du workflow
    const workflowStep = await db
      .select()
      .from(project_analysis_progress)
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(project_analysis_progress.stepId, analysisStep[0].id) // Utiliser le vrai stepId
        )
      )
      .limit(1);

    if (workflowStep.length > 0) {
      await db
        .update(project_analysis_progress)
        .set({
          status: 'completed',
          content: JSON.stringify(validatedData.strengthsAndWeaknesses),
          completedAt: new Date(),
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, workflowStep[0].id));
    }

    // ‚úÖ D√©clencher automatiquement l'√©tape suivante seulement si pas en mode debug
    let nextStepTriggered = false;
    if (skipAutoTrigger !== 'true') {
      const triggerResult = await triggerNextWorkflowStep(projectUniqueId, 4);
      nextStepTriggered = triggerResult.success;
      if (!triggerResult.success) {
        console.warn(`‚ö†Ô∏è √âchec du d√©clenchement automatique de l'√©tape suivante: ${triggerResult.error}`);
      } else {
        console.log(`‚úÖ √âtape suivante d√©clench√©e automatiquement (mode normal)`);
      }
    } else {
      console.log(`üîß Mode debug activ√© - √©tape suivante non d√©clench√©e automatiquement`);
    }

    res.status(200).json({
      success: true,
      message: 'Forces et faiblesses re√ßues et enregistr√©es avec succ√®s',
      workflowStepId: workflowStep.length > 0 ? workflowStep[0].id : null,
      itemsCreated: createdItems.length,
      data: createdItems.map((item: any) => ({
        id: item.id,
        type: item.type,
        title: item.title,
        status: item.status
      })),
      nextStepTriggered,
      debugMode: skipAutoTrigger === 'true'
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'RECEIVE_STRENGTHS_WEAKNESSES_ERROR'
    });
  }
};

/**
 * Endpoint pour recevoir le message final de l'IA (√âtape 5)
 * @route POST /api/workflow/final-message/:projectUniqueId
 */
export const receiveFinalMessage = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;
    const validatedData = FinalMessagePayloadSchema.parse({ 
      ...req.body, 
      projectUniqueId 
    });

    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({ 
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // R√©cup√©rer la session la plus r√©cente du projet pour y ajouter la conversation
    const recentSession = await db
      .select()
      .from(sessions)
      .where(eq(sessions.projectId, project[0].id))
      .orderBy(desc(sessions.createdAt))
      .limit(1);

    if (recentSession.length === 0) {
      return res.status(404).json({ 
        error: 'Aucune session trouv√©e pour ce projet',
        code: 'SESSION_NOT_FOUND'
      });
    }

    // ‚úÖ GESTION MESSAGES : Logique draft vs nouveau message
    // V√©rifier d'abord l'√©tat du workflow step pour cette √©tape
    const analysisStep = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 5),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    let isDraftMode = false;
    if (analysisStep.length > 0) {
      const workflowStep = await db
        .select()
        .from(project_analysis_progress)
        .where(
          and(
            eq(project_analysis_progress.projectId, project[0].id),
            eq(project_analysis_progress.stepId, analysisStep[0].id)
          )
        )
        .limit(1);
      
      // Si l'√©tape est encore "in_progress", on est en mode draft
      isDraftMode = workflowStep.length > 0 && workflowStep[0].status === 'in_progress';
    }

    if (isDraftMode) {
      // MODE DRAFT : Supprimer les messages IA existants pour cette session et les remplacer
      await db
        .delete(conversations)
        .where(and(
          eq(conversations.sessionId, recentSession[0].id),
          eq(conversations.sender, 'IA')
        ));
      
      console.log(`üóëÔ∏è Messages IA existants supprim√©s (mode draft) pour le projet ${projectUniqueId}`);
    }

    // Cr√©er le nouveau message (que ce soit en mode draft ou nouveau)
    await db
      .insert(conversations)
      .values({
        sessionId: recentSession[0].id,
        sessionDate: new Date(),
        sender: 'IA',
        message: validatedData.message,
        attachments: [],
      });

    console.log(`‚úÖ ${isDraftMode ? 'Message draft mis √† jour' : 'Nouveau message cr√©√©'} pour le projet ${projectUniqueId}`);

    // Utiliser l'√©tape d'analyse d√©j√† r√©cup√©r√©e plus haut (analysisStep)
    if (analysisStep.length === 0) {
      return res.status(404).json({ 
        error: '√âtape d\'analyse non trouv√©e (order = 5)',
        code: 'ANALYSIS_STEP_NOT_FOUND'
      });
    }

    const workflowStep = await db
      .select()
      .from(project_analysis_progress)
      .where(
        and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(project_analysis_progress.stepId, analysisStep[0].id) // Utiliser le vrai stepId
        )
      )
      .limit(1);

    if (workflowStep.length > 0) {
      await db
        .update(project_analysis_progress)
        .set({
          status: 'completed',
          content: 'Message final cr√©√© dans conversations',
          completedAt: new Date(),
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, workflowStep[0].id));
    }

    // Pour l'√©tape 5 (derni√®re √©tape), pas de d√©clenchement automatique
    // Le workflow est maintenant termin√©
    console.log(`‚úÖ Workflow termin√© pour le projet: ${projectUniqueId}`);

    res.status(200).json({
      success: true,
      message: 'Message final re√ßu et enregistr√© dans les conversations avec succ√®s. Workflow termin√©.',
      workflowStepId: workflowStep.length > 0 ? workflowStep[0].id : null,
      workflowCompleted: true
    });
  } catch (error) {
    res.status(500).json({ 
      error: (error as Error).message,
      code: 'RECEIVE_FINAL_MESSAGE_ERROR'
    });
  }
};

/**
 * G√©n√®re un ZIP avec tous les documents d'un projet et l'envoie √† Manus
 * @route POST /api/workflow/upload-zip-from-url
 */
export const uploadZipFromUrl = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.body;

    if (!projectUniqueId) {
      return res.status(400).json({
        error: 'ProjectUniqueId est requis',
        code: 'MISSING_PROJECT_UNIQUE_ID'
      });
    }

    console.log(`üöÄ D√©but de l'upload ZIP pour le projet: ${projectUniqueId}`);
    console.log(`üìã Payload re√ßu:`, JSON.stringify(req.body, null, 2));

    // R√©cup√©rer le projet
    console.log(`üîç Recherche du projet: ${projectUniqueId}`);
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      console.log(`‚ùå Projet non trouv√©: ${projectUniqueId}`);
      return res.status(404).json({
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    console.log(`‚úÖ Projet trouv√©: ${project[0].projectName} (ID: ${project[0].id})`);

    // R√©cup√©rer tous les documents du projet via les sessions
    console.log(`üîç Recherche des documents pour le projet ${project[0].id}...`);
    
    // D'abord, voir tous les documents (peu importe le statut)
    const allDocuments = await db
      .select({
        fileName: documents.fileName,
        url: documents.url,
        status: documents.status,
        sessionId: documents.sessionId,
      })
      .from(documents)
      .innerJoin(sessions, eq(documents.sessionId, sessions.id))
      .where(eq(sessions.projectId, project[0].id));
    
    console.log(`üìä Tous les documents du projet (${allDocuments.length} total):`);
    allDocuments.forEach((doc, index) => {
      console.log(`   ${index + 1}. ${doc.fileName} - Status: ${doc.status} - URL: ${doc.url}`);
    });
    
    // Maintenant, filtrer seulement les PROCESSED
    const projectDocuments = allDocuments.filter(doc => doc.status === 'PROCESSED');
    console.log(`üìÑ Documents avec statut PROCESSED: ${projectDocuments.length}/${allDocuments.length}`);

    if (projectDocuments.length === 0) {
      console.log(`‚ùå Aucun document trouv√© pour le projet ${projectUniqueId}`);
      return res.status(400).json({
        error: 'Aucun document trouv√© pour ce projet',
        code: 'NO_DOCUMENTS_FOUND'
      });
    }

    console.log(`üìÑ ${projectDocuments.length} documents trouv√©s pour le projet ${projectUniqueId}`);
    projectDocuments.forEach((doc, index) => {
      console.log(`   ${index + 1}. ${doc.fileName} - ${doc.url}`);
    });

    // Cr√©er le ZIP et l'uploader vers S3
    console.log(`üì¶ Cr√©ation du ZIP √† partir de ${projectDocuments.length} documents...`);
    const zipResult = await createZipFromDocuments(projectDocuments, projectUniqueId);
    console.log(`‚úÖ ZIP cr√©√© avec succ√®s:`, {
      fileName: zipResult.fileName,
      s3Url: zipResult.s3Url,
      size: zipResult.size,
      hash: zipResult.hash
    });

    // R√©cup√©rer le prompt de l'√©tape 0 (Upload des documents)
    console.log(`üîç Recherche de l'√©tape 0 dans analysis_steps...`);
    const step0 = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 0),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step0.length === 0) {
      console.log(`‚ùå √âtape 0 non trouv√©e dans analysis_steps`);
      return res.status(500).json({
        error: '√âtape 0 non trouv√©e dans le workflow. Ex√©cutez le script add-step-0-upload-zip.ts',
        code: 'STEP_0_NOT_FOUND'
      });
    }

    console.log(`‚úÖ √âtape 0 trouv√©e: "${step0[0].name}" (ID: ${step0[0].id})`);
    console.log(`üìù Prompt original (premiers 200 chars): ${step0[0].prompt.substring(0, 200)}...`);

    // R√©cup√©rer le prompt dynamique depuis la base de donn√©es
    let dynamicMessage = step0[0].prompt;
    
    // Remplacer les variables dynamiques dans le message
    console.log(`üîÑ Remplacement des variables dynamiques:`);
    console.log(`   - {projectUniqueId} ‚Üí ${projectUniqueId}`);
    console.log(`   - {documentCount} ‚Üí ${projectDocuments.length}`);
    
    dynamicMessage = dynamicMessage.replace(/{projectUniqueId}/g, projectUniqueId);
    dynamicMessage = dynamicMessage.replace(/{documentCount}/g, projectDocuments.length.toString());
    
    console.log(`üìù Message final (premiers 200 chars): ${dynamicMessage.substring(0, 200)}...`);

    // Utiliser l'infrastructure existante pour envoyer √† l'API Python
    // M√™me format que external-tools.ts mais avec zip_url
    const payload = {
      zip_url: zipResult.s3Url,
      message: dynamicMessage,
      platform: 'manus',
      projectUniqueId
    };

    console.log(`üì¶ Payload pr√©par√© pour l'API Python:`);
    console.log(`   - zip_url: ${payload.zip_url}`);
    console.log(`   - platform: ${payload.platform}`);
    console.log(`   - projectUniqueId: ${payload.projectUniqueId}`);
    console.log(`   - message (premiers 200 chars): ${payload.message.substring(0, 200)}...`);
    console.log(`   - taille compl√®te du message: ${payload.message.length} caract√®res`);

    // R√©cup√©rer la configuration API Python
    let pythonApiUrl = process.env.AI_INTERFACE_ACTION_URL || process.env.AI_INTERFACE_URL;
    
    if (!pythonApiUrl) {
      console.log(`üîç Recherche de la configuration API Python dans la base de donn√©es...`);
      const [config] = await db
        .select()
        .from(api_configurations)
        .where(and(
          eq(api_configurations.name, 'Python API'),
          eq(api_configurations.isActive, true)
        ));
      
      pythonApiUrl = config?.url || 'http://localhost:8000';
      console.log(`üîß URL r√©cup√©r√©e depuis la DB: ${pythonApiUrl}`);
    } else {
      console.log(`üîß URL r√©cup√©r√©e depuis les variables d'environnement: ${pythonApiUrl}`);
    }

    console.log(`üì° Envoi du ZIP √† l'API Python: ${pythonApiUrl}/upload-zip-from-url`);
    console.log(`üìÑ Payload JSON complet:`);
    console.log(JSON.stringify(payload, null, 2));

    let response;
    try {
      response = await axios.post(`${pythonApiUrl}/upload-zip-from-url`, payload, {
        headers: {
          'Content-Type': 'application/json',
        },
        timeout: 60000, // 60 secondes pour l'upload du ZIP
      });
    } catch (axiosError: any) {
      console.error(`‚ùå Erreur lors de l'appel √† l'API Python:`, axiosError.message);
      console.error(`üìä Status:`, axiosError.response?.status);
      console.error(`üìÑ Response data:`, axiosError.response?.data);
      
      // Pour l'instant, on continue m√™me si l'API Python √©choue
      // TODO: G√©rer proprement cette erreur
      console.log(`‚ö†Ô∏è Continuons malgr√© l'erreur de l'API Python...`);
      
      // Simuler une r√©ponse pour que le workflow continue
      response = {
        data: {
          conversation_url: 'https://error-fallback-url.com',
          status: 'error_but_continuing'
        }
      };
    }

    console.log(`üì® R√©ponse re√ßue de l'API Python:`, response.status, response.statusText);
    console.log(`üìÑ Corps de la r√©ponse:`, JSON.stringify(response.data, null, 2));

    // G√©rer les r√©ponses normales et les fallbacks
    const conversationUrl = response.data?.conversation_url || 'https://fallback-conversation-url.com';
    const isErrorFallback = response.data?.status === 'error_but_continuing';

    // Mettre √† jour l'√©tape 0 comme termin√©e
    await db
      .update(project_analysis_progress)
      .set({
        status: 'completed',
        content: `ZIP upload√©: ${zipResult.fileName} (${zipResult.size} bytes)${isErrorFallback ? ' - Fallback apr√®s erreur API Python' : ''}`,
        manusConversationUrl: conversationUrl,
        completedAt: new Date(),
        updatedAt: new Date(),
      })
      .where(and(
        eq(project_analysis_progress.projectId, project[0].id),
        eq(project_analysis_progress.stepId, step0[0].id)
      ));

    // Sauvegarder l'URL du ZIP dans la table projects
    console.log(`üíæ Sauvegarde de l'URL du ZIP dans le projet: ${zipResult.s3Url}`);
    await db
      .update(projects)
      .set({
        zipUrl: zipResult.s3Url,
        updatedAt: new Date(),
      })
      .where(eq(projects.id, project[0].id));

    // D√©clencher automatiquement l'√©tape suivante seulement si ce n'est pas un fallback d'erreur
    let triggerResult = { success: false };
    if (!isErrorFallback) {
      triggerResult = await triggerNextWorkflowStep(projectUniqueId, 0);
    }

    console.log(`‚úÖ ZIP trait√© pour le projet: ${projectUniqueId}`);
    console.log(`üîó URL conversation: ${conversationUrl}`);
    if (isErrorFallback) {
      console.log(`‚ö†Ô∏è Mode fallback activ√© suite √† erreur API Python`);
    }

    res.status(200).json({
      message: isErrorFallback ? 'ZIP cr√©√© mais erreur lors de l\'envoi √† Manus (mode fallback)' : 'ZIP cr√©√© et envoy√© avec succ√®s √† Manus',
      projectUniqueId,
      zipUrl: zipResult.s3Url,
      zipFileName: zipResult.fileName,
      zipSize: zipResult.size,
      documentCount: projectDocuments.length,
      conversationUrl,
      nextStepTriggered: triggerResult.success,
      isErrorFallback
    });

  } catch (error: any) {
    const { projectUniqueId } = req.body;
    console.error(`‚ùå Erreur lors de l'upload ZIP pour le projet ${projectUniqueId || 'INCONNU'}:`);
    console.error(`üìÑ Type d'erreur:`, error.constructor.name);
    console.error(`üìÑ Message d'erreur:`, error.message);
    
    if (error.response) {
      console.error(`üìä Status de l'erreur HTTP:`, error.response.status);
      console.error(`üìã Headers de l'erreur:`, error.response.headers);
      console.error(`üìÑ Corps de l'erreur:`, error.response.data);
    }
    
    if (error.request) {
      console.error(`üì° Requ√™te qui a √©chou√©:`, error.request);
    }
    
    console.error(`üîç Stack trace:`, error.stack);
    
    res.status(500).json({
      error: error.message || 'Erreur lors de l\'upload ZIP',
      code: 'UPLOAD_ZIP_ERROR'
    });
  }
};

/**
 * G√©n√®re uniquement le ZIP des documents sans d√©clencher l'IA
 * @route POST /api/workflow/generate-zip-only
 */
export const generateZipOnly = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.body;

    if (!projectUniqueId) {
      return res.status(400).json({
        error: 'ProjectUniqueId est requis',
        code: 'MISSING_PROJECT_UNIQUE_ID'
      });
    }

    console.log(`üì¶ G√©n√©ration ZIP uniquement pour le projet: ${projectUniqueId}`);

    // R√©cup√©rer le projet
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      console.log(`‚ùå Projet non trouv√©: ${projectUniqueId}`);
      return res.status(404).json({
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    console.log(`‚úÖ Projet trouv√©: ${project[0].projectName} (ID: ${project[0].id})`);

    // R√©cup√©rer tous les documents du projet via les sessions
    console.log(`üîç Recherche des documents pour le projet ${project[0].id}...`);
    
    // D'abord, voir tous les documents (peu importe le statut)
    const allDocuments = await db
      .select({
        fileName: documents.fileName,
        url: documents.url,
        status: documents.status,
        sessionId: documents.sessionId,
      })
      .from(documents)
      .innerJoin(sessions, eq(documents.sessionId, sessions.id))
      .where(eq(sessions.projectId, project[0].id));
    
    console.log(`üìä Tous les documents du projet (${allDocuments.length} total):`);
    allDocuments.forEach((doc, index) => {
      console.log(`   ${index + 1}. ${doc.fileName} - Status: ${doc.status} - URL: ${doc.url}`);
    });
    
    // Maintenant, filtrer seulement les PROCESSED
    const projectDocuments = allDocuments.filter(doc => doc.status === 'PROCESSED');
    console.log(`üìÑ Documents avec statut PROCESSED: ${projectDocuments.length}/${allDocuments.length}`);

    if (projectDocuments.length === 0) {
      console.log(`‚ùå Aucun document PROCESSED trouv√© pour le projet ${projectUniqueId}`);
      return res.status(400).json({
        error: 'Aucun document trait√© trouv√© pour ce projet',
        code: 'NO_PROCESSED_DOCUMENTS_FOUND'
      });
    }

    console.log(`üìÑ ${projectDocuments.length} documents trouv√©s pour le projet ${projectUniqueId}`);
    projectDocuments.forEach((doc, index) => {
      console.log(`   ${index + 1}. ${doc.fileName} - ${doc.url}`);
    });

    // Cr√©er le ZIP et l'uploader vers S3
    console.log(`üì¶ Cr√©ation du ZIP √† partir de ${projectDocuments.length} documents...`);
    const zipResult = await createZipFromDocuments(projectDocuments, projectUniqueId);
    console.log(`‚úÖ ZIP cr√©√© avec succ√®s:`, {
      fileName: zipResult.fileName,
      s3Url: zipResult.s3Url,
      size: zipResult.size,
      hash: zipResult.hash
    });

    // V√©rifier si le ZIP semble anormalement petit (probablement des fichiers manquants)
    const expectedMinSize = projectDocuments.length * 10000; // ~10KB par document minimum
    if (zipResult.size < expectedMinSize && projectDocuments.length > 2) {
      console.warn(`‚ö†Ô∏è ZIP suspicieusement petit: ${zipResult.size} bytes pour ${projectDocuments.length} documents`);
      console.warn(`‚ö†Ô∏è Taille attendue minimum: ${expectedMinSize} bytes`);
      console.warn(`‚ö†Ô∏è Possible probl√®me: fichiers manquants sur S3`);
    }

    // Sauvegarder l'URL du ZIP dans la table projects
    console.log(`üíæ Sauvegarde de l'URL du ZIP dans le projet: ${zipResult.s3Url}`);
    await db
      .update(projects)
      .set({
        zipUrl: zipResult.s3Url,
        updatedAt: new Date(),
      })
      .where(eq(projects.id, project[0].id));

    console.log(`‚úÖ ZIP g√©n√©r√© avec succ√®s pour le projet: ${projectUniqueId}`);

    res.status(200).json({
      message: 'ZIP g√©n√©r√© avec succ√®s',
      projectUniqueId,
      zipUrl: zipResult.s3Url,
      zipFileName: zipResult.fileName,
      zipSize: zipResult.size,
      documentCount: projectDocuments.length
    });

  } catch (error: any) {
    const { projectUniqueId } = req.body;
    console.error(`‚ùå Erreur lors de la g√©n√©ration du ZIP pour le projet ${projectUniqueId || 'INCONNU'}:`);
    console.error(`üìÑ Type d'erreur:`, error.constructor.name);
    console.error(`üìÑ Message d'erreur:`, error.message);
    
    if (error.response) {
      console.error(`üìä Status de l'erreur HTTP:`, error.response.status);
      console.error(`üìã Headers de l'erreur:`, error.response.headers);
      console.error(`üìÑ Corps de l'erreur:`, error.response.data);
    }
    
    console.error(`üîç Stack trace:`, error.stack);
    
    res.status(500).json({
      error: error.message || 'Erreur lors de la g√©n√©ration du ZIP',
      code: 'GENERATE_ZIP_ERROR'
    });
  }
};

/**
 * D√©clenche manuellement l'√©tape 1 (Analyse globale) du workflow
 * @route POST /api/workflow/trigger-step-1/:projectUniqueId
 */
export const triggerStep1Analysis = async (req: Request, res: Response): Promise<any> => {
  try {
    const { projectUniqueId } = req.params;

    if (!projectUniqueId) {
      return res.status(400).json({
        error: 'ProjectUniqueId est requis',
        code: 'MISSING_PROJECT_UNIQUE_ID'
      });
    }

    console.log(`üöÄ D√©clenchement manuel de l'√©tape 1 pour le projet: ${projectUniqueId}`);

    // R√©cup√©rer le projet
    const project = await db
      .select()
      .from(projects)
      .where(eq(projects.projectUniqueId, projectUniqueId))
      .limit(1);

    if (project.length === 0) {
      return res.status(404).json({
        error: 'Projet non trouv√©',
        code: 'PROJECT_NOT_FOUND'
      });
    }

    // R√©cup√©rer l'√©tape 1
    const step1 = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 1),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    if (step1.length === 0) {
      return res.status(500).json({
        error: '√âtape 1 non trouv√©e dans le workflow',
        code: 'STEP_1_NOT_FOUND'
      });
    }

    // V√©rifier que l'√©tape 1 existe dans le workflow du projet
    const workflowStep1 = await db
      .select()
      .from(project_analysis_progress)
      .where(and(
        eq(project_analysis_progress.projectId, project[0].id),
        eq(project_analysis_progress.stepId, step1[0].id)
      ))
      .limit(1);

    if (workflowStep1.length === 0) {
      return res.status(404).json({
        error: '√âtape 1 non trouv√©e dans le workflow du projet',
        code: 'WORKFLOW_STEP_1_NOT_FOUND'
      });
    }

    // R√©cup√©rer l'√©tape 0 et marquer comme termin√©e si elle ne l'est pas d√©j√†
    const step0 = await db
      .select()
      .from(analysis_steps)
      .where(and(
        eq(analysis_steps.order, 0),
        eq(analysis_steps.isActive, 1)
      ))
      .limit(1);

    let conversationUrl: string | undefined;
    
    if (step0.length > 0) {
      const workflowStep0 = await db
        .select()
        .from(project_analysis_progress)
        .where(and(
          eq(project_analysis_progress.projectId, project[0].id),
          eq(project_analysis_progress.stepId, step0[0].id)
        ))
        .limit(1);

      if (workflowStep0.length > 0) {
        // R√©cup√©rer l'URL de conversation de l'√©tape 0
        if (workflowStep0[0].manusConversationUrl) {
          conversationUrl = workflowStep0[0].manusConversationUrl;
        }

        // Marquer l'√©tape 0 comme termin√©e si elle ne l'est pas d√©j√†
        if (workflowStep0[0].status !== 'completed') {
          await db
            .update(project_analysis_progress)
            .set({
              status: 'completed',
              content: 'Analyse des documents ZIP termin√©e - d√©clenchement de l\'√©tape suivante',
              completedAt: new Date(),
              updatedAt: new Date(),
            })
            .where(eq(project_analysis_progress.id, workflowStep0[0].id));

          console.log(`‚úÖ √âtape 0 marqu√©e comme termin√©e automatiquement pour le projet: ${projectUniqueId}`);
        }
      }
    }

    // Mettre l'√©tape 1 en statut 'in_progress'
    await db
      .update(project_analysis_progress)
      .set({
        status: 'in_progress',
        updatedAt: new Date(),
      })
      .where(eq(project_analysis_progress.id, workflowStep1[0].id));

    // Envoyer le prompt de l'√©tape 1 √† l'IA
    const result = await sendPromptToAI(
      step1[0].prompt,
      projectUniqueId,
      step1[0].id,
      step1[0].name,
      conversationUrl
    );

    if (result.success && result.conversationUrl) {
      // Mettre √† jour l'√©tape 1 avec l'URL de conversation
      await db
        .update(project_analysis_progress)
        .set({
          manusConversationUrl: result.conversationUrl,
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, workflowStep1[0].id));

      console.log(`‚úÖ √âtape 1 d√©clench√©e avec succ√®s pour le projet: ${projectUniqueId}`);
      console.log(`üîó URL conversation: ${result.conversationUrl}`);

      res.status(200).json({
        message: '√âtape 1 (Analyse globale) d√©clench√©e avec succ√®s',
        projectUniqueId,
        stepId: step1[0].id,
        stepName: step1[0].name,
        conversationUrl: result.conversationUrl,
        status: 'in_progress'
      });
    } else {
      // Marquer l'√©tape comme √©chou√©e avec le message d'erreur
      await db
        .update(project_analysis_progress)
        .set({
          status: 'failed',
          content: `Erreur lors de l'envoi du prompt √† l'API Python: ${result.error}`,
          updatedAt: new Date(),
        })
        .where(eq(project_analysis_progress.id, workflowStep1[0].id));

      console.error(`‚ùå √âtape 1 marqu√©e comme √©chou√©e pour le projet: ${projectUniqueId}`);
      console.error(`üìÑ Erreur: ${result.error}`);

      res.status(200).json({
        message: '√âtape 1 d√©clench√©e mais √©chec de l\'API Python',
        projectUniqueId,
        stepId: step1[0].id,
        stepName: step1[0].name,
        status: 'failed',
        error: result.error
      });
    }

  } catch (error) {
    console.error('‚ùå Erreur lors du d√©clenchement de l\'√©tape 1:', error);
    res.status(500).json({
      error: (error as Error).message,
      code: 'TRIGGER_STEP_1_ERROR'
    });
  }
};

 