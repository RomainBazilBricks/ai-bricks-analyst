import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import crypto from 'crypto';
import dotenv from 'dotenv';
import archiver from 'archiver';
import { Readable } from 'stream';
import yauzl from 'yauzl';

dotenv.config();

// Configuration du client S3
export const s3Client = new S3Client({
  region: process.env.AWS_S3_REGION?.replace(/"/g, '') || 'eu-north-1',
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID?.replace(/"/g, '') || '',
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY?.replace(/"/g, '') || '',
  },
});

const BUCKET_NAME = process.env.AWS_S3_BUCKET_NAME!;



/**
 * T√©l√©charge un fichier depuis une URL et l'upload vers S3
 * Si c'est un fichier ZIP, le d√©zippe et upload les fichiers individuels
 */
export async function uploadFileFromUrl(
  fileUrl: string,
  projectUniqueId: string,
  fileName?: string
): Promise<{
  s3Url: string;
  fileName: string;
  hash: string;
  mimeType: string;
  size: number;
  extractedFiles?: Array<{ s3Url: string; fileName: string; hash: string; mimeType: string; size: number }>;
}> {
  try {
    // T√©l√©charger le fichier depuis l'URL
    const response = await fetch(fileUrl);
    if (!response.ok) {
      throw new Error(`Failed to fetch file from ${fileUrl}: ${response.statusText}`);
    }

    let buffer = Buffer.from(await response.arrayBuffer());
    let contentType = response.headers.get('content-type') || 'application/octet-stream';
    
    // G√©n√©rer le nom de fichier s'il n'est pas fourni
    const extractedFileName = extractFileNameFromUrl(fileUrl);
    const headerFileName = extractFileNameFromHeaders(response.headers);
    let finalFileName = fileName || extractedFileName || headerFileName || `document-${Date.now()}`;
    
    console.log(`üîç DEBUG uploadFileFromUrl:`);
    console.log(`  - fileUrl: ${fileUrl}`);
    console.log(`  - fileName param: ${fileName}`);
    console.log(`  - extractedFileName: ${extractedFileName}`);
    console.log(`  - headerFileName: ${headerFileName}`);
    console.log(`  - finalFileName: ${finalFileName}`);
    console.log(`  - taille originale: ${(buffer.length / 1024 / 1024).toFixed(2)}MB`);
    
    // D√©tecter les fichiers ZIP
    const isZipFile = contentType === 'application/zip' || 
                     finalFileName.toLowerCase().endsWith('.zip') ||
                     contentType === 'application/x-zip-compressed';
    
    if (isZipFile) {
      console.log(`üì¶ ZIP d√©tect√©: ${finalFileName} (${(buffer.length / 1024 / 1024).toFixed(2)}MB) - D√©zippage √† venir`);
    }
    
    // Calculer le hash du fichier pour d√©tecter les doublons
    const hash = crypto.createHash('sha256').update(buffer).digest('hex');
    
    if (isZipFile) {
      console.log(`üì¶ Fichier ZIP d√©tect√©: ${finalFileName}, d√©zippage automatique (ZIP non stock√©)...`);
      
      try {
        // D√©zipper le fichier et extraire les fichiers (en filtrant les images)
        const extractedFiles = await unzipFile(buffer, projectUniqueId);
        
        if (extractedFiles.length === 0) {
          console.log(`‚ö†Ô∏è Aucun fichier valide trouv√© dans le ZIP ${finalFileName}`);
          // Traiter comme un fichier normal si aucun fichier extrait
        } else {
          // Upload les fichiers extraits vers S3 avec d√©duplication
          const uploadResults = await uploadExtractedFilesToS3(extractedFiles, projectUniqueId);
          
          console.log(`‚úÖ ZIP d√©zipp√©: ${uploadResults.length} fichiers extraits et upload√©s (ZIP original non stock√©)`);
          
          // ‚ö†Ô∏è IMPORTANT: Ne pas stocker le ZIP original, retourner seulement les fichiers extraits
          // On retourne un objet factice pour maintenir la compatibilit√© de l'API
          return {
            s3Url: '', // Pas d'URL car le ZIP n'est pas stock√©
            fileName: `${finalFileName} (d√©zipp√©)`,
            hash: 'zip-extracted',
            mimeType: 'application/zip-extracted',
            size: 0, // Taille 0 car le ZIP n'est pas stock√©
            extractedFiles: uploadResults,
          };
        }
      } catch (zipError) {
        console.error(`‚ùå Erreur lors du traitement du ZIP ${finalFileName}:`, zipError);
        console.log(`üìÑ Traitement comme fichier normal...`);
        // Continuer avec le traitement normal si le d√©zippage √©choue
      }
    }
    
    // Traitement normal pour les fichiers non-ZIP ou en cas d'erreur de d√©zippage
    const s3Key = `projects/${projectUniqueId}/${hash}-${finalFileName}`;
    
    // Upload vers S3
    const putCommand = new PutObjectCommand({
      Bucket: BUCKET_NAME,
      Key: s3Key,
      Body: buffer,
      ContentType: contentType,
      // ACL supprim√© car le bucket ne les autorise pas
      Metadata: {
        originalUrl: fileUrl,
        projectUniqueId,
        uploadedAt: new Date().toISOString(),
      },
    });

    await s3Client.send(putCommand);

    // G√©n√©rer l'URL S3
    const s3Url = `https://${BUCKET_NAME}.s3.${process.env.AWS_S3_REGION || 'eu-north-1'}.amazonaws.com/${s3Key}`;

    return {
      s3Url,
      fileName: finalFileName,
      hash,
      mimeType: contentType,
      size: buffer.length,
    };
  } catch (error) {
    console.error(`Error uploading file from ${fileUrl}:`, error);
    throw new Error(`Failed to upload file from URL: ${(error as Error).message}`);
  }
}

/**
 * G√©n√®re une URL pr√©-sign√©e pour acc√©der √† un fichier S3
 */
export async function generatePresignedUrl(s3Key: string, expiresIn = 3600): Promise<string> {
  const command = new GetObjectCommand({
    Bucket: BUCKET_NAME,
    Key: s3Key,
  });

  return await getSignedUrl(s3Client, command, { expiresIn });
}

/**
 * G√©n√®re une URL pr√©-sign√©e depuis une URL S3 compl√®te
 */
export async function generatePresignedUrlFromS3Url(s3Url: string, expiresIn = 3600): Promise<string> {
  try {
    const s3Key = extractS3KeyFromUrl(s3Url);
    return await generatePresignedUrl(s3Key, expiresIn);
  } catch (error) {
    console.error('Erreur lors de la g√©n√©ration de l\'URL pr√©-sign√©e:', error);
    throw new Error(`Failed to generate presigned URL: ${(error as Error).message}`);
  }
}

/**
 * Extrait le nom de fichier depuis une URL
 */
function extractFileNameFromUrl(url: string): string | null {
  try {
    const urlObj = new URL(url);
    const pathname = urlObj.pathname;
    const fileName = pathname.split('/').pop();
    
    if (!fileName || fileName.length === 0) {
      return null;
    }
    
    // D√©coder l'URL pour g√©rer les caract√®res sp√©ciaux
    const decodedFileName = decodeURIComponent(fileName);
    
    // Nettoyer le nom de fichier (supprimer les caract√®res non autoris√©s)
    const cleanFileName = decodedFileName.replace(/[<>:"/\\|?*]/g, '_');
    
    return cleanFileName;
  } catch {
    return null;
  }
}

/**
 * Extrait le nom de fichier depuis les headers HTTP (Content-Disposition)
 */
function extractFileNameFromHeaders(headers: Headers): string | null {
  try {
    const contentDisposition = headers.get('content-disposition');
    if (!contentDisposition) {
      return null;
    }
    
    // Chercher filename= ou filename*= dans le header
    const filenameMatch = contentDisposition.match(/filename[^;=\n]*=((['"]).*?\2|[^;\n]*)/);
    if (!filenameMatch || !filenameMatch[1]) {
      return null;
    }
    
    let fileName = filenameMatch[1].trim();
    
    // Supprimer les guillemets si pr√©sents
    if ((fileName.startsWith('"') && fileName.endsWith('"')) || 
        (fileName.startsWith("'") && fileName.endsWith("'"))) {
      fileName = fileName.slice(1, -1);
    }
    
    // D√©coder si n√©cessaire
    const decodedFileName = decodeURIComponent(fileName);
    
    // Nettoyer le nom de fichier
    const cleanFileName = decodedFileName.replace(/[<>:"/\\|?*]/g, '_');
    
    return cleanFileName;
  } catch {
    return null;
  }
}

/**
 * V√©rifie si un fichier avec le m√™me hash existe d√©j√† pour un projet
 */
export function getS3KeyFromHash(projectUniqueId: string, hash: string, fileName: string): string {
  return `projects/${projectUniqueId}/${hash}-${fileName}`;
}

/**
 * Extrait la cl√© S3 depuis une URL S3 compl√®te
 */
export function extractS3KeyFromUrl(s3Url: string): string {
  try {
    const url = new URL(s3Url);
    let key = url.pathname.substring(1); // Enlever le "/" initial
    
    // IMPORTANT: D√©coder l'URL pour √©viter les probl√®mes d'encoding avec AWS SDK
    key = decodeURIComponent(key);
    
    console.log(`üîë S3 Key original: ${url.pathname.substring(1)}`);
    console.log(`üîë S3 Key d√©cod√©: ${key}`);
    
    return key;
  } catch {
    throw new Error('Invalid S3 URL format');
  }
}

/**
 * Extrait la cl√© S3 depuis une URL S3 compl√®te sans d√©coder (pour les cl√©s stock√©es encod√©es)
 */
export function extractS3KeyFromUrlRaw(s3Url: string): string {
  try {
    const url = new URL(s3Url);
    const key = url.pathname.substring(1); // Enlever le "/" initial, sans d√©coder
    
    console.log(`üîë S3 Key brut: ${key}`);
    
    return key;
  } catch {
    throw new Error('Invalid S3 URL format');
  }
}

/**
 * T√©l√©charge un fichier depuis S3
 */
export async function downloadFileFromS3(s3Url: string): Promise<Buffer> {
  let s3Response;
  
  // Essayer d'abord avec la cl√© d√©cod√©e
  try {
    const s3Key = extractS3KeyFromUrl(s3Url);
    const command = new GetObjectCommand({
      Bucket: BUCKET_NAME,
      Key: s3Key,
    });
    s3Response = await s3Client.send(command);
  } catch (s3Error: any) {
    console.error(`‚ùå Erreur S3 avec cl√© d√©cod√©e pour ${s3Url}:`, s3Error.name);
    
    if (s3Error.name === 'NoSuchKey') {
      // Essayer avec la cl√© brute (non d√©cod√©e)
      try {
        const rawS3Key = extractS3KeyFromUrlRaw(s3Url);
        console.log(`üîÑ Tentative avec cl√© brute: ${rawS3Key}`);
        
        const commandRaw = new GetObjectCommand({
          Bucket: BUCKET_NAME,
          Key: rawS3Key,
        });
        s3Response = await s3Client.send(commandRaw);
        console.log(`‚úÖ Succ√®s avec cl√© brute: ${rawS3Key}`);
      } catch (rawError: any) {
        console.error(`‚ùå Erreur S3 avec cl√© brute pour ${s3Url}:`, rawError.name);
        throw new Error(`File not found with decoded or raw key: ${s3Url}`);
      }
    } else {
      throw s3Error;
    }
  }

  if (!s3Response.Body) {
    throw new Error('No body in S3 response');
  }

  // Convertir le stream en buffer
  const chunks: Uint8Array[] = [];
  const reader = s3Response.Body as Readable;
  
  return new Promise((resolve, reject) => {
    reader.on('data', (chunk) => chunks.push(chunk));
    reader.on('error', reject);
    reader.on('end', () => resolve(Buffer.concat(chunks)));
  });
}

/**
 * Cr√©e un fichier ZIP √† partir d'une liste de documents et l'upload vers S3
 */
export async function createZipFromDocuments(
  documents: Array<{ fileName: string; url: string }>,
  projectUniqueId: string,
  projectData?: { conversation?: string; fiche?: string }
): Promise<{ s3Url: string; fileName: string; hash: string; size: number }> {
  try {
    console.log(`üì¶ Cr√©ation d'un ZIP pour le projet ${projectUniqueId} avec ${documents.length} documents`);
    
    // Filtrer les images avant de cr√©er le ZIP
    const filteredDocuments = filterNonImageDocuments(documents);

    // Cr√©er l'archive ZIP en m√©moire
    const archive = archiver('zip', {
      zlib: { level: 9 } // Compression maximale
    });

    const chunks: Buffer[] = [];
    
    // Collecter les chunks du ZIP
    archive.on('data', (chunk) => {
      chunks.push(chunk);
    });

    // Promesse pour attendre la fin de l'archivage
    const zipPromise = new Promise<Buffer>((resolve, reject) => {
      archive.on('end', () => {
        const zipBuffer = Buffer.concat(chunks);
        console.log(`‚úÖ ZIP cr√©√© avec succ√®s: ${zipBuffer.length} bytes`);
        resolve(zipBuffer);
      });

      archive.on('error', (error) => {
        console.error('‚ùå Erreur lors de la cr√©ation du ZIP:', error);
        reject(error);
      });
    });

      // Compteurs pour le suivi
  let successCount = 0;
  let failureCount = 0;
  const failedDocuments: string[] = [];

  // Ajouter chaque document au ZIP
  for (const doc of filteredDocuments) {
    try {
      console.log(`üìÑ Tentative d'ajout du document: ${doc.fileName}`);
      console.log(`üîó URL S3: ${doc.url}`);
      
      const fileBuffer = await downloadFileFromS3(doc.url);
      
      const fileSizeMB = (fileBuffer.length / 1024 / 1024).toFixed(2);
      
      // Nettoyer le nom de fichier pour √©viter les probl√®mes de chemin
      const cleanFileName = doc.fileName.replace(/[<>:"/\\|?*]/g, '_');
      archive.append(fileBuffer, { name: cleanFileName });
      
      successCount++;
      console.log(`‚úÖ Document ajout√© avec succ√®s: ${doc.fileName} (${fileSizeMB}MB) (${successCount}/${filteredDocuments.length})`);
    } catch (error) {
      failureCount++;
      failedDocuments.push(doc.fileName);
      console.warn(`‚ùå Impossible d'ajouter le document ${doc.fileName} (${failureCount} √©checs):`, error);
      // Continuer avec les autres documents m√™me si un √©choue
    }
  }

  console.log(`üìä R√©sum√© de l'ajout des documents:`);
  console.log(`   ‚úÖ Succ√®s: ${successCount}/${filteredDocuments.length}`);
  console.log(`   ‚ùå √âchecs: ${failureCount}/${filteredDocuments.length}`);
  if (failedDocuments.length > 0) {
    console.log(`   üìã Documents √©chou√©s: ${failedDocuments.join(', ')}`);
  }

    // Ajouter les fichiers conversation.txt et fiche.txt si les donn√©es sont disponibles et non vides
    if (projectData?.conversation && projectData.conversation.trim() !== '') {
      try {
        const conversationIntro = "Voici un aper√ßu de la conversation entre les membres de l'√©quipe Bricks et le porteur de projet";
        const conversationContent = `${conversationIntro}\n\n${projectData.conversation.trim()}`;
        const conversationBuffer = Buffer.from(conversationContent, 'utf-8');
        
        archive.append(conversationBuffer, { name: 'conversation.txt' });
        console.log(`‚úÖ Fichier conversation.txt ajout√© au ZIP (${conversationBuffer.length} bytes)`);
      } catch (error) {
        console.warn(`‚ùå Impossible d'ajouter conversation.txt:`, error);
        // L'erreur ne bloque pas le processus, on continue
      }
    } else {
      console.log(`‚ÑπÔ∏è Aucune conversation valide disponible pour ce projet`);
    }

    if (projectData?.fiche && projectData.fiche.trim() !== '') {
      try {
        const ficheIntro = "Voici ce qu'√† indiqu√© le porteur de projet dans sa r√©daction en autonomie de la fiche opportunit√© pour pr√©senter le projet aux investisseurs";
        const ficheContent = `${ficheIntro}\n\n${projectData.fiche.trim()}`;
        const ficheBuffer = Buffer.from(ficheContent, 'utf-8');
        
        archive.append(ficheBuffer, { name: 'fiche.txt' });
        console.log(`‚úÖ Fichier fiche.txt ajout√© au ZIP (${ficheBuffer.length} bytes)`);
      } catch (error) {
        console.warn(`‚ùå Impossible d'ajouter fiche.txt:`, error);
        // L'erreur ne bloque pas le processus, on continue
      }
    } else {
      console.log(`‚ÑπÔ∏è Aucune fiche valide disponible pour ce projet`);
    }

    // Finaliser l'archive
    archive.finalize();

    // Attendre que le ZIP soit cr√©√©
    const zipBuffer = await zipPromise;

    // Calculer le hash du ZIP
    const hash = crypto.createHash('sha256').update(zipBuffer).digest('hex');

    // G√©n√©rer le nom du fichier ZIP
    const zipFileName = `${projectUniqueId}-documents-${Date.now()}.zip`;
    const s3Key = `projects/${projectUniqueId}/zips/${hash}-${zipFileName}`;

    // Upload du ZIP vers S3
    const putCommand = new PutObjectCommand({
      Bucket: BUCKET_NAME,
      Key: s3Key,
      Body: zipBuffer,
      ContentType: 'application/zip',
      // ACL retir√© - le bucket ne les autorise plus du tout
      Metadata: {
        projectUniqueId,
        documentCount: filteredDocuments.length.toString(),
        originalDocumentCount: documents.length.toString(),
        imagesFiltered: (documents.length - filteredDocuments.length).toString(),
        createdAt: new Date().toISOString(),
      },
    });

    await s3Client.send(putCommand);

    // G√©n√©rer l'URL S3
    const s3Url = `https://${BUCKET_NAME}.s3.${process.env.AWS_S3_REGION || 'eu-north-1'}.amazonaws.com/${s3Key}`;

    console.log(`‚úÖ ZIP upload√© vers S3: ${s3Url}`);

    return {
      s3Url,
      fileName: zipFileName,
      hash,
      size: zipBuffer.length,
    };
  } catch (error) {
    console.error('‚ùå Erreur lors de la cr√©ation du ZIP:', error);
    throw new Error(`Failed to create ZIP: ${(error as Error).message}`);
  }
}

/**
 * Extensions d'images √† filtrer lors de la cr√©ation du ZIP
 */
const IMAGE_EXTENSIONS = [
  '.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.heic', '.tiff', '.tif', '.svg', '.ico'
];

/**
 * V√©rifie si un fichier est une image bas√© sur son extension
 */
function isImageFile(fileName: string): boolean {
  const extension = fileName.toLowerCase().split('.').pop();
  return extension ? IMAGE_EXTENSIONS.includes(`.${extension}`) : false;
}

/**
 * Filtre les documents pour exclure les images
 */
export function filterNonImageDocuments(documents: Array<{ fileName: string; url: string }>): Array<{ fileName: string; url: string }> {
  const filteredDocuments = documents.filter(doc => !isImageFile(doc.fileName));
  
  const originalCount = documents.length;
  const filteredCount = filteredDocuments.length;
  const imageCount = originalCount - filteredCount;
  
  console.log(`üñºÔ∏è Filtrage des images: ${originalCount} documents ‚Üí ${filteredCount} documents (${imageCount} images exclues)`);
  
  if (imageCount > 0) {
    const imageFiles = documents.filter(doc => isImageFile(doc.fileName)).map(doc => doc.fileName);
    console.log(`üìã Images exclues: ${imageFiles.join(', ')}`);
  }
  
  return filteredDocuments;
}

/**
 * D√©zippe un fichier ZIP et retourne la liste des fichiers extraits
 */
export async function unzipFile(
  zipBuffer: Buffer,
  projectUniqueId: string
): Promise<Array<{ fileName: string; buffer: Buffer; mimeType: string }>> {
  return new Promise((resolve, reject) => {
    const extractedFiles: Array<{ fileName: string; buffer: Buffer; mimeType: string }> = [];
    
    yauzl.fromBuffer(zipBuffer, { lazyEntries: true }, (err, zipfile) => {
      if (err) {
        console.error('‚ùå Erreur lors de l\'ouverture du ZIP:', err);
        return reject(err);
      }
      
      if (!zipfile) {
        return reject(new Error('Impossible d\'ouvrir le fichier ZIP'));
      }
      
      console.log(`üì¶ D√©but du d√©zippage: ${zipfile.entryCount} entr√©es trouv√©es`);
      
      zipfile.readEntry();
      
      zipfile.on('entry', (entry) => {
        // Ignorer les dossiers
        if (entry.fileName.endsWith('/')) {
          console.log(`üìÅ Dossier ignor√©: ${entry.fileName}`);
          zipfile.readEntry();
          return;
        }
        
        // Ignorer les fichiers syst√®me et cach√©s
        const fileName = entry.fileName.split('/').pop() || '';
        if (fileName.startsWith('.') || fileName.startsWith('__MACOSX')) {
          console.log(`üö´ Fichier syst√®me ignor√©: ${entry.fileName}`);
          zipfile.readEntry();
          return;
        }
        
        // Ignorer les images
        if (isImageFile(fileName)) {
          console.log(`üñºÔ∏è Image ignor√©e: ${entry.fileName}`);
          zipfile.readEntry();
          return;
        }
        
        console.log(`üìÑ Extraction du fichier: ${entry.fileName} (${entry.uncompressedSize} bytes)`);
        
        zipfile.openReadStream(entry, (err, readStream) => {
          if (err) {
            console.error(`‚ùå Erreur lors de l'ouverture du stream pour ${entry.fileName}:`, err);
            zipfile.readEntry();
            return;
          }
          
          if (!readStream) {
            console.error(`‚ùå Stream vide pour ${entry.fileName}`);
            zipfile.readEntry();
            return;
          }
          
          const chunks: Buffer[] = [];
          
          readStream.on('data', (chunk) => {
            chunks.push(chunk);
          });
          
          readStream.on('end', () => {
            const fileBuffer = Buffer.concat(chunks);
            
            // D√©terminer le type MIME bas√© sur l'extension
            let mimeType = 'application/octet-stream';
            const extension = fileName.toLowerCase().split('.').pop();
            
            switch (extension) {
              case 'pdf':
                mimeType = 'application/pdf';
                break;
              case 'doc':
                mimeType = 'application/msword';
                break;
              case 'docx':
                mimeType = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document';
                break;
              case 'xls':
                mimeType = 'application/vnd.ms-excel';
                break;
              case 'xlsx':
                mimeType = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet';
                break;
              case 'ppt':
                mimeType = 'application/vnd.ms-powerpoint';
                break;
              case 'pptx':
                mimeType = 'application/vnd.openxmlformats-officedocument.presentationml.presentation';
                break;
              case 'txt':
                mimeType = 'text/plain';
                break;
              case 'csv':
                mimeType = 'text/csv';
                break;
            }
            
            extractedFiles.push({
              fileName: fileName,
              buffer: fileBuffer,
              mimeType: mimeType
            });
            
            console.log(`‚úÖ Fichier extrait: ${fileName} (${fileBuffer.length} bytes, ${mimeType})`);
            zipfile.readEntry();
          });
          
          readStream.on('error', (err) => {
            console.error(`‚ùå Erreur lors de la lecture du stream pour ${entry.fileName}:`, err);
            zipfile.readEntry();
          });
        });
      });
      
      zipfile.on('end', () => {
        console.log(`‚úÖ D√©zippage termin√©: ${extractedFiles.length} fichiers extraits`);
        resolve(extractedFiles);
      });
      
      zipfile.on('error', (err) => {
        console.error('‚ùå Erreur lors du d√©zippage:', err);
        reject(err);
      });
    });
  });
}

/**
 * Upload les fichiers extraits d'un ZIP vers S3
 */
export async function uploadExtractedFilesToS3(
  extractedFiles: Array<{ fileName: string; buffer: Buffer; mimeType: string }>,
  projectUniqueId: string,
  existingFiles?: Array<{ fileName: string; hash: string }> // Pour la d√©duplication
): Promise<Array<{ s3Url: string; fileName: string; hash: string; mimeType: string; size: number }>> {
  const uploadResults: Array<{ s3Url: string; fileName: string; hash: string; mimeType: string; size: number }> = [];
  
  console.log(`üì§ Upload de ${extractedFiles.length} fichiers extraits vers S3...`);
  
  for (const file of extractedFiles) {
    try {
      // Calculer le hash du fichier
      const hash = crypto.createHash('sha256').update(file.buffer).digest('hex');
      
      // Nettoyer le nom de fichier
      const cleanFileName = file.fileName.replace(/[<>:"/\\|?*]/g, '_');
      
      // üîç D√âDUPLICATION: V√©rifier si ce fichier existe d√©j√† (par hash ET nom)
      if (existingFiles) {
        const isDuplicateByHash = existingFiles.some(existing => existing.hash === hash);
        const isDuplicateByName = existingFiles.some(existing => existing.fileName === cleanFileName);
        
        if (isDuplicateByHash || isDuplicateByName) {
          console.log(`‚ö†Ô∏è Fichier dupliqu√© ignor√©: ${cleanFileName}`);
          console.log(`   - Dupliqu√© par hash: ${isDuplicateByHash ? 'OUI' : 'NON'}`);
          console.log(`   - Dupliqu√© par nom: ${isDuplicateByName ? 'OUI' : 'NON'}`);
          continue; // Passer au fichier suivant
        }
      }
      
      // Cr√©er la cl√© S3
      const s3Key = `projects/${projectUniqueId}/${hash}-${cleanFileName}`;
      
      // Upload vers S3
      const putCommand = new PutObjectCommand({
        Bucket: BUCKET_NAME,
        Key: s3Key,
        Body: file.buffer,
        ContentType: file.mimeType,
        // ACL supprim√© car le bucket ne les autorise pas
        Metadata: {
          projectUniqueId,
          originalFileName: file.fileName,
          extractedFromZip: 'true',
          uploadedAt: new Date().toISOString(),
        },
      });
      
      await s3Client.send(putCommand);
      
      // G√©n√©rer l'URL S3
      const s3Url = `https://${BUCKET_NAME}.s3.${process.env.AWS_S3_REGION || 'eu-north-1'}.amazonaws.com/${s3Key}`;
      
      uploadResults.push({
        s3Url,
        fileName: cleanFileName,
        hash,
        mimeType: file.mimeType,
        size: file.buffer.length,
      });
      
      console.log(`‚úÖ Fichier upload√©: ${cleanFileName} ‚Üí ${s3Url}`);
      
    } catch (error) {
      console.error(`‚ùå Erreur lors de l'upload de ${file.fileName}:`, error);
      // Continuer avec les autres fichiers m√™me si un √©choue
    }
  }
  
  console.log(`üìä Upload termin√©: ${uploadResults.length}/${extractedFiles.length} fichiers upload√©s avec succ√®s`);
  
  return uploadResults;
} 